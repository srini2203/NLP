# -*- coding: utf-8 -*-
"""nlp1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/185qjXGKfRnx3xD6XCPneetLv9RIL8ZM1
"""

import nltk
from nltk.tokenize import PunktSentenceTokenizer
from nltk.corpus import webtext

nltk.download('webtext')
nltk.download('punkt')


text=webtext.raw()
sent_tokenizer=PunktSentenceTokenizer(text)
sent_1=sent_tokenizer.tokenize(text)
print(sent_1[0])

from nltk.corpus import stopwords

nltk.download('stopwords')

english_stops=set(stopwords.words('english'))

words=['I','am','a','good','boy']

filtered_words=[word for word in words if word not in english_stops]
print(filtered_words)

import nltk
from nltk.corpus import wordnet as wn

nltk.download('wordnet')
nltk.download('omw-1.4')

syn=wn.synsets('dog')[2]

print(syn.name())
print(syn.definition())
print(syn.examples())

from nltk.stem import WordNetLemmatizer


lemmatizer=WordNetLemmatizer()

print(lemmatizer.lemmatize('libraries'))
print(lemmatizer.lemmatize('running',pos='v'))

# Import Necessary Packages
import nltk
from nltk import word_tokenize, pos_tag, ne_chunk

# Download required NLTK datasets
nltk.download('punkt')
nltk.download('maxent_ne_chunker_tab')
nltk.download('words')
nltk.download('averaged_perceptron_tagger_eng')

# Sample input text
text = "Mark Zuckerberg is one of the founders of Facebook, a company from the United States."

# Tokenize the text
words = word_tokenize(text)

# Perform part-of-speech tagging
tags = pos_tag(words)

# Perform named entity recognition
ner_tags = ne_chunk(tags)

# Extract and print named entities
for entity in ner_tags:
    if isinstance(entity, nltk.Tree):  # Check if the entity is a named entity
        entity_words = [word for word, tag in entity.leaves()]
        entity_name = " ".join(entity_words)
        entity_label = entity.label()
        print(f"Entity: {entity_name}, Label: {entity_label}")