# -*- coding: utf-8 -*-
"""collocation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AXU8p3rZWDh7-dWg5XnwF_mM2uIfOCbl
"""

import nltk
import re

RE_pattern=[
    (r'won\'t','I wont'),
    (r'can\'t','I cant'),
    (r'I\'am','I am'),
    (r'(\w+)\'ll','\g<1> will'),
    (r'(\w+)\'ve','\g<1>have'),
    (r'(\w+)\'s','\g<1> is'),
    (r'(\w+)\'re','\g<1> are'),
]
class REReplacer(object):
  def _init_(self,pattern=RE_pattern):
    self.pattern=((compile(regex),repl) for (regex,repl) in RE_pattern)
  def replace(self,text):
    s=text
    for(pattern,repl)in self.pattern:
      s=re.sub(pattern,repl,s)
      return s

nltk.download('stopwords')

import nltk
import re
import string
import math
import numpy as np
from nltk.corpus import stopwords

critical_value=float(input("Enter critical input value:"))

stop_words=set(stopwords.words('english'))

file=open("input.txt","r")
text=file.read()
print(text)

nltk.download('punkt_tab')
sent=nltk.sent_tokenize(text)

sent1=[]
rep_word=REReplacer()
for i in sent:
  n=rep_word.replace(i)
  n=n.translate(str.maketrans('','',string.punctuation))
  sent1.append(n)

ws=[]
for j in sent1:
  ws.append(nltk.word_tokenize(j))
for s in sent:
  ws.append(s)

texts=[]
for w in ws:
  if w not in stopwords:
    texts.append(w)
print(texts)
N=len(texts)

vc=[]
for v in texts:
  if v not in vc:
    vc.append(v)
voc_len=len(vc)
print(vc)
print("Unique words:",voc_len)
print("Total words:",N)

def chi_sq(w1,w2,c1,c2,c12):
  expected=(c1/N)*(c2/n)*N
  observed=c12
  numerator=(observed-expected)**2
  denominator=expected
  chi_sq=numerator/denominator
  print(f"Chi-square for ({w1},{w2})")
  if chi_sq>critical_value:
    print("Significant")